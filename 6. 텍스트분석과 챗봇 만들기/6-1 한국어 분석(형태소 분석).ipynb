{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석 (Morphological Analysis)\n",
    "\n",
    "* 자연 언어의 문장을 '형태소'라는 의미를 갖는 최소 단위로 분할하고 품사를 판별하는 작업\n",
    "    * 영어는 쉽다!!!! 단어를 공백으로 구분이 가능하니깐! 아시아 계열~ 특히 한국어 문장에는 단어와 조사가 붙어 있어 공백으로 구분이 안됩니다.\n",
    "\n",
    "* NLP (Natural Language Processing, 자연어처리)\n",
    "    * 텍스트에서 의미있는 정보를 분석, 추출하고 이해하는 일련의 기술집합입니다.\n",
    "    * 다양한 NLP 응용사례\n",
    "        * 텍스트 요약 (ex: Summly)\n",
    "        * 자동 질의응답 시스템 (ex: Wolfram Alpha)\n",
    "        * 대화 시스템 (ex: Apple Siri)\n",
    "        * 기계 번역 (ex: Google Translate)\n",
    "\n",
    "* 필요한 라이브러리들!!!\n",
    "\n",
    "    * Java 설치 (환경변수 설정 꼭 해주세요!)\n",
    "\n",
    "    * 한국어 정보처리를 위한 파이썬 패키지 KoNLPy\n",
    "        * 코엔엘파이 / KoNLPy(http://konlpy.org/ko/latest/)\n",
    "        * GPL licence\n",
    "        * 설치 : http://konlpy.org/ko/latest/install/\n",
    "        * tag packages : http://konlpy.org/ko/latest/api/konlpy.tag/\n",
    "\n",
    "    * 한글 형태소 분석기 바인더 Mecab (필수 아님)\n",
    "        * Window mecab를 지원 안함\n",
    "        * Mac은 homebrew로 설치하세요 (brew install mecab)\n",
    "        * https://docs.google.com/spreadsheets/d/1-9blXKjtjeKZqsf4NzHeYJCrr49-nXeRF6D80udfcwY/edit#gid=589544265\n",
    "      \n",
    "    * JPype 설치\n",
    "        * 파이썬 프로그램이 Java class 라이브러리에 접근할 수 있도록 해준다.\n",
    "        * JPype1 0.6.2 : Python Package Index\n",
    "        * github : originell/jpype: Friendly jpype fork with focus on easy installation.\n",
    "        * 공식 문서 : JPype documentation — JPype 0.6.2 documentation \n",
    "        * http://jpype.readthedocs.io/en/latest/install.html#install\n",
    "        * Mac OSX는 여기를 참조하세요 -> http://corazzon.github.io/Konlpy_JPype_install_struggle\n",
    "            * pip install JPype1-py3 실행하심 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['상수역', '근처', '에', '있', '는', '머신', '러닝', '스터디', '장소', '좀', '알려', '주', '세요', '.']\n",
      "['평창', '올림픽', '인기', '종목', '컬링']\n",
      "[('홍대', 'NNG'), ('역', 'NNG'), ('에서', 'JKB'), ('상수역', 'NNP'), ('까지', 'JX'), ('걸어서', 'VV+EC'), ('얼마나', 'MAG'), ('걸리', 'VV'), ('나요', 'EF'), ('?', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "# mecab example\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "p1 = mecab.morphs(u'상수역 근처에 있는 머신러닝 스터디 장소 좀 알려주세요.')\n",
    "p2 = mecab.nouns(u'평창 올림픽에서 가장 인기 있는 종목은 컬링입니다.')\n",
    "p3 = mecab.pos(u'홍대역에서 상수역 까지 걸어서 얼마나 걸리나요?')\n",
    "\n",
    "print(p1)\n",
    "print(p2)\n",
    "print(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가다', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "# Twitter example \n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "# p1 = twitter.morphs(\"아버지 가방에 들어가신다\", norm=True, stem=True)\n",
    "# p2 = twitter.nouns(\"아버지 가방에 들어가신다\", norm=True, stem=True)\n",
    "p3 = twitter.pos(\"아버지 가방에 들어가신다\", norm=True, stem=True)\n",
    "\n",
    "# print(p1)\n",
    "# print(p2)\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 출현 빈도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utf-16 인코딩으로 파일을 열고 글자를 출력하기\n",
    "fp = codecs.open(\"test.txt\", \"r\", encoding=\"utf-16\")\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "body = soup.select_one(\"body > text\")\n",
    "test = body.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 텍스트 한 줄씩 처리하기\n",
    "twitter = Twitter()\n",
    "word_dic = {}\n",
    "lines = test.split(\"\\n\")\n",
    "for line in lines:\n",
    "    malist = twitter.pos(line)\n",
    "    for word[1] in malist:\n",
    "        if word[0] == \"Noun\":  # 명사 여부 확인\n",
    "            word_dic[word[0]] = 0\n",
    "        word_dic[word[0]] += 1 # 카운트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 많이 사용된 명사 출력하기\n",
    "keys = sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "for word, count in keys[:50]:\n",
    "    print(\"{0}({1})\".format(word, count), end=\"\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
