{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크로스 밸리데이션\n",
    "    * 지금까지 교제에서 해왔었던 방식은 1분할 방식이였음\n",
    "        * 훈련전용 데이터와 테스트 전용 데이터로 분할한 뒤 서로 크로스로 학습의 타당성을 검증하는 방법\n",
    "    * K 분할 교차 검증 ( K-fold cross vaildation )\n",
    "        * K는 특정 숫자인데 보통 5~10을 사용 \n",
    "        * 훈련 데이터를 K개로 나누고 그중에 한묶음을 검증데이터로 사용하고 나머지 묶음을 훈련 데이터로 사용하여 학습을 시킴\n",
    "        * K번의 정답률을 구할 수 있으므로 더욱 신뢰성있는 값을 도출할 수있는 장점이 있음.\n",
    "            * 운 나쁘게 분류하기 어려운 샘플들이 모두 테스트 세트에 들어가는 최악의 케이스 방지하도록 함.\n",
    "        * 데이터셋에 있는 모든 샘플이 테스트될 기회를 갖도록 하는 것.\n",
    "![Alt text](https://tensorflowkorea.files.wordpress.com/2016/10/07_cross_validation_diagram.png)\n",
    "\n",
    "\n",
    "크로스 밸리데이션은 훈련과 테스트를 위해 모든 데이터를 사용\n",
    "이 방식 이면에 있는 아이디어는 테스트 데이터를 위해 데이터셋에서 비교적 큰 부분을 따로 떼어 놓지 않고 \n",
    "많은 훈련 데이터를 사용하여 비관적 편향을 감소시키려는 목적이 있는것 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import random, re\n",
    "\n",
    "# 붓꽃의 CSV 파일 읽어 들이기 \n",
    "lines = open('iris.csv', 'r', encoding='utf-8').read().split(\"\\n\")\n",
    "\n",
    "# 문자열 데이터 숫자변환 람다함수 \n",
    "f_tonum = lambda n : float(n) if re.match(r'^[0-9\\.]+$', n) else n\n",
    "# 쉽표로 데이터 뽑아주는 람다함수 ( 공백제거 후 ',' 스플릿)\n",
    "f_cols  = lambda li: list(map(f_tonum, li.strip().split(',')))\n",
    "csv = list(map(f_cols, lines))\n",
    "\n",
    "# 헤더 제거하기 (epalLength,SepalWidth,PetalLength,PetalWidth,Name)\n",
    "del csv[0] \n",
    "\n",
    "print(type(csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "<class 'list'>\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 K개로 분할하기 \n",
    "\n",
    "K = 5 \n",
    "csvk = [ [] for i in range(K) ]\n",
    "print(len(csvk))\n",
    "print(type(csvk[0])) \n",
    "\n",
    "print(len(csv))\n",
    "for i in range(len(csv)):\n",
    "    csvk[i % K].append(csv[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "각각의 정답률 = [0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0]\n",
      "평균 정답률 = 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# 리스트를 훈련 전용 데이터와 테스트 전용 데이터로 분할하는 함수\n",
    "def split_data_label(rows):\n",
    "    data = []; label = []\n",
    "    for row in rows:\n",
    "        data.append(row[0:4])\n",
    "        label.append(row[4])\n",
    "    return (data, label)\n",
    "\n",
    "# 정답률 구하는 함수 \n",
    "def calc_score(test, train):\n",
    "    test_f, test_l = split_data_label(test)\n",
    "    train_f, train_l = split_data_label(train)\n",
    "    # 학습시키고 정답률 구하기\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_f, train_l)\n",
    "    pre = clf.predict(test_f)\n",
    "    return metrics.accuracy_score(test_l, pre)\n",
    "\n",
    "# K개로 분할해서 정답률 구하기\n",
    "score_list = []\n",
    "for testc in csvk:\n",
    "    # testc 이외의 데이터를 훈련 전용 데이터로 사용하기\n",
    "    trainc = []\n",
    "    for i in csvk:\n",
    "        if i != testc: trainc += i\n",
    "    sc = calc_score(testc, trainc)\n",
    "    score_list.append(sc)\n",
    "    \n",
    "print(\"각각의 정답률 =\", score_list)\n",
    "print(\"평균 정답률 =\", sum(score_list) / len(score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn 의 크로스 밸리데이션\n",
    "\n",
    "* API \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "    * cross_val_score() 함수 사용 및 이해는 소스를 통해서 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각각의 정답률 = [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "평균 정답률 = 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm, metrics, model_selection\n",
    "import random, re\n",
    "\n",
    "# 붓꽃의 CSV 데이터 읽어 들이기 \n",
    "csv = pd.read_csv('iris.csv')\n",
    "\n",
    "# 리스트를 훈련 전용 데이터와 테스트 전용 데이터로 분할하기 \n",
    "data = csv[[\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\"]]\n",
    "# print(data)\n",
    "label = csv[\"Name\"]\n",
    "# print(label)\n",
    "\n",
    "# 크로스 밸리데이션하기\n",
    "clf = svm.SVC()\n",
    "scores = model_selection.cross_val_score(clf, data, label, cv=5)\n",
    "print(\"각각의 정답률 =\", scores)\n",
    "print(\"평균 정답률 =\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각각의 정답률 = [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "평균 정답률 = 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import svm, metrics, model_selection\n",
    "\n",
    "# scikit-learn 의 붓꽃 데이터셋을 제공해줌 ( 다른 데이터셋도 많다. )\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "iris = load_iris()\n",
    "\n",
    "clf = svm.SVC()\n",
    "scores = model_selection.cross_val_score(clf, iris.data, iris.target, cv=3)\n",
    "\n",
    "print(\"각각의 정답률 =\", scores)\n",
    "print(\"평균 정답률 =\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 검증의 상세 옵션\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "\n",
    "* KFold\n",
    " * 데이터 섞어주는 기능 추가 \n",
    "* ShuffleSplit\n",
    " * 반복횟수, 훈련세트나 테스트 세트의 크기를 독립적으로 조절할 때 유용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris 레이블:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 순서대로 K개의 폴드로 나누는것이 항상 좋은 결과를 주지 않음.\n",
    "# 결과를 보더라도 순차적으로 K=3으로 했을 경우 첫번째 반복에서 0%으로 나올 활률이 있음 \n",
    "# A와 B의 구성이 90대 10으로 구성이 나뉜다면 A의 샘플만 가진 폴드가 생길수 있기때문에 분류기의 전체성능이 왜곡하게 됨 \n",
    "print(\"Iris 레이블:\\n{}\".format(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 점수:\n",
      "[0. 0. 0.]\n",
      "교차 검증 점수:\n",
      "[0.9  0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "print(\"교차 검증 점수:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))\n",
    "\n",
    "#  데이터를 섞어서 샘플의 순서를 뒤죽박죽으로 만들어야 함.\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"교차 검증 점수:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 점수:\n",
      "[0.86666667 0.97333333 0.92       0.90666667 0.89333333 0.92\n",
      " 0.93333333 0.94666667 0.94666667 0.97333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# 데이터셋의 50%를 훈련세트, 50%를 테스트 세트로 10번 반복 분할 처리 \n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)\n",
    "print(\"교차 검증 점수:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM ( Support Vector Machine )\n",
    "http://bskyvision.com/163\n",
    "\n",
    "#### 매개변수\n",
    " * C : 데이터 샘플들이 다른 클래스에 놓이는 것을 허용하는 정도를 결정\n",
    " * gamma : 결정 경계의 곡률을 결정\n",
    "\n",
    "\n",
    "\n",
    "# 그리드 서치 ( GridSearchCV )\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "![Alt text](http://cfile23.uf.tistory.com/image/27795E4F5915750E064D09)\n",
    "\n",
    "### 동작\n",
    "* 클래스 객체의 fit매서드를 호출하면 grid search를 사용하여 자동으로 복수개의 내부모형을 생성하고 이를 모두 실행시켜서 최적의 파라미터를 찾아주고 다음 속성의 저장함, 따라서 시간이 꽤 오래걸리기 때문에 n_jobs을 이용하여 처리하면 된다고 함 \n",
    "* n_jobs(디폴트 값은 1) : 병렬 계산할 프로세스 수 지정 ( \n",
    "    * 이 값을 증가시키면 내부적으로 멀티 프로세스를 사용하여 그리드서치를 수행 \n",
    "    * 만약 CPU 코어의 수가 충분하다면 n_jobs를 늘릴 수록 속도가 증가\n",
    "    * 값을 -1로 지정할 경우 자동으로 코어의 수에 맞게 프로세스 수를 정해줌 \n",
    "\n",
    "### 속성\n",
    "* grid_scores_\n",
    "    * param_grid 의 모든 파리미터 조합에 대한 성능 결과. 각각의 원소는 다음 요소로 이루어진 튜플이다.\n",
    "    * parameters: 사용된 파라미터\n",
    "    * mean_validation_score: 교차 검증(cross-validation) 결과의 평균값\n",
    "    * cv_validation_scores: 모든 교차 검증(cross-validation) 결과\n",
    "* best_score_\n",
    "    * 최고 점수\n",
    "* best_params_\n",
    "    * 최고 점수를 낸 파라미터\n",
    "* best_estimator_\n",
    "    * 최고 점수를 낸 파라미터를 가진 모형\n",
    "    \n",
    "### 정리\n",
    "* SVM는 딥러닝이 나온 후에도 여전히 환영받는 머신러닝 알고리즘 ( 가볍기 때문 )\n",
    "* SVM 알고리즘 중에서 가장 성능이 괜찮고좋은 성능을 얻으려면 매개변수인 C와 gamma를 잘 조정해 줘야하는것이 키포인트 \n",
    "* 각 알고리즘에는 여러 매개변수를 지정하는데 적잘한 매개변수를 지정하면 정답률이 올라가게 됨. \n",
    "* 그리드 서치는 더 좋은 매개변수를 자동으로 찾는 방법임\n",
    "    * 각 매개변수를 적당한 범위 내부에서 변경하면서 가장 성능 좋을 때의 값을 찾는 방법 \n",
    "    * 매개변수 튜닝 작업임\n",
    "* 기존의 손글씨 인식 프로그램을 비교하여 매개변수를 어떻게 튜닝하면 좋은 결과가 나오는지가 이 파트의 핵심임\n",
    "\n",
    "\n",
    "#### 참고링크\n",
    "* https://datascienceschool.net/view-notebook/ff4b5d491cc34f94aea04baca86fbef8/\n",
    "* http://cyan91.tistory.com/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 그리드 서치\n",
    "* SVC 에 구현된 SVM 사용 \n",
    " * http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    " * default : RBF (Radial Basis Function) 커널 SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트의 크기: 112   테스트 세트의 크기: 38\n",
      "최고 점수: 0.97\n",
      "최적 파라미터: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import svm, metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"훈련 세트의 크기: {}   테스트 세트의 크기: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # 매개변수의 각 조합에 대해 SVC를 훈련시킵니다\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # 테스트 세트로 SVC를 평가합니다\n",
    "        score = svm.score(X_test, y_test)\n",
    "        \n",
    "        # 점수가 더 높으면 매개변수와 함께 기록합니다\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "            \n",
    "print(\"최고 점수: {:.2f}\".format(best_score))\n",
    "print(\"최적 파라미터: {}\".format(best_parameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이전에 사용했던 손글씨 인식 프로그램\n",
    "* 그리드 서치를 했을때와 안했을때의 정답률이 어떻게 개선되는지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 정답률 = 0.7884231536926147\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, svm, metrics\n",
    "\n",
    "def load_csv(fname):\n",
    "    labels = []\n",
    "    images = []\n",
    "    with open(fname, \"r\") as f:\n",
    "        for line in f:\n",
    "            cols = line.split(\",\")\n",
    "            if len(cols) < 2: continue\n",
    "            labels.append(int(cols.pop(0)))\n",
    "            vals = list(map(lambda n: int(n) / 256, cols))\n",
    "            images.append(vals)\n",
    "    return {\"labels\":labels, \"images\":images}\n",
    "\n",
    "data = load_csv(\"./mnist/train.csv\")\n",
    "test = load_csv(\"./mnist/t10k.csv\")\n",
    "\n",
    "# 학습하기 \n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"images\"], data[\"labels\"])\n",
    "# 예측하기 \n",
    "predict = clf.predict(test[\"images\"])\n",
    "# 결과 확인하기 \n",
    "ac_score = metrics.accuracy_score(test[\"labels\"], predict)\n",
    "print(\">>> 정답률 =\", ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리드 서치를 활용한 정답률 개선 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> grid_scores = [mean: 0.86813, std: 0.00225, params: {'C': 1, 'kernel': 'linear'}, mean: 0.86813, std: 0.00225, params: {'C': 10, 'kernel': 'linear'}, mean: 0.86813, std: 0.00225, params: {'C': 100, 'kernel': 'linear'}, mean: 0.86813, std: 0.00225, params: {'C': 1000, 'kernel': 'linear'}, mean: 0.79421, std: 0.00831, params: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}, mean: 0.14885, std: 0.04624, params: {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}, mean: 0.87013, std: 0.00918, params: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}, mean: 0.79820, std: 0.00966, params: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}, mean: 0.87612, std: 0.01185, params: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}, mean: 0.87013, std: 0.00788, params: {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}, mean: 0.87612, std: 0.01185, params: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}, mean: 0.87013, std: 0.00505, params: {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}]\n",
      "> best_score = 0.8761238761238761\n",
      "> best_params = {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "> best_estimator = SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      ">>> 정답률 = 0.872255489021956\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, svm, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# 그리드 서치 매개변수 설정 ( 매개변수 후보들 ) \n",
    "params = [\n",
    "    {\"C\": [1,10,100,1000], \"kernel\":[\"linear\"]},\n",
    "    {\"C\": [1,10,100,1000], \"kernel\":[\"rbf\"], \"gamma\":[0.001, 0.0001]}\n",
    "]\n",
    "\n",
    "# 그리드 서치 수행 \n",
    "clf = GridSearchCV( svm.SVC(), params, n_jobs=-1 )\n",
    "clf.fit(data[\"images\"], data[\"labels\"])\n",
    "print(\"> grid_scores =\", clf.grid_scores_)\n",
    "print(\"> best_score =\", clf.best_score_)\n",
    "print(\"> best_params =\", clf.best_params_)\n",
    "print(\"> best_estimator =\", clf.best_estimator_)\n",
    "\n",
    "# 테스트 데이터 확인하기 \n",
    "pre = clf.predict(test[\"images\"])\n",
    "ac_score = metrics.accuracy_score(pre, test[\"labels\"])\n",
    "print(\">>> 정답률 =\", ac_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
