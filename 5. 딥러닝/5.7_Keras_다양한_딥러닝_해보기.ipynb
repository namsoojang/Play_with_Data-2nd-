{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    " - Machine Learning 라이브러리 Theano와 TesnorFlow를 Wrapping한 라이브러리 (https://deeplearning4j.org/kr/compare-dl4j-torch7-pylearn)\n",
    "  - Theano는 Numpy와 같은 다차원 배열을 다루는 라이브러리\n",
    "  - Tensorflow는 Theano를 대체하기 위해 나온 라이브러리\n",
    " - 케라스는 파이썬으로 구현된 쉽고 간결한 딥러닝 라이브러리입니다. 딥러닝 비전문가라도 각자 분야에서 손쉽게 딥러닝 모델을 개발하고 활용할 수 있도록 케라스는 직관적인 API를 제공하고 있습니다. 내부적으로는 텐서플로우(TensorFlow), 티아노(Theano), CNTK 등의 딥러닝 전용 엔진이 구동되지만 케라스 사용자는 복잡한 내부 엔진을 알 필요는 없습니다. 직관적인 API로 쉽게 다층퍼셉트론 모델, 컨볼루션 신경망 모델, 순환 신경망 모델 또는 이를 조합한 모델은 물론 다중 입력 또는 다중 출력 등 다양한 구성을 할 수 있습니다. (https://tykimos.github.io/2017/01/27/Keras_Talk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras로 비만도 판정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd, numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\#Study\\\\Play_with_Data_2nd\\\\5. 딥러닝'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI 데이터를 읽어 들이고 정규화하기 --- (※1)\n",
    "csv = pd.read_csv(\"./ch5/bmi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>62</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177</td>\n",
       "      <td>61</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187</td>\n",
       "      <td>48</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>60</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight   label\n",
       "0     142      62     fat\n",
       "1     142      73     fat\n",
       "2     177      61  normal\n",
       "3     187      48    thin\n",
       "4     153      60     fat"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csv.shape)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.62   0.71 ]\n",
      " [ 0.73   0.71 ]\n",
      " [ 0.61   0.885]\n",
      " ..., \n",
      " [ 0.37   0.965]\n",
      " [ 0.51   0.975]\n",
      " [ 0.67   0.815]]\n"
     ]
    }
   ],
   "source": [
    "# 몸무게와 키 데이터 - 정규화: 데이터의 범위를 일치시키거나 분포를 유사하게 만들어 주기\n",
    "csv[\"weight\"] /= 100\n",
    "csv[\"height\"] /= 200\n",
    "X = csv[[\"weight\", \"height\"]].as_matrix() # --- (※1a)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas의 DataFrame형을 Keras에서는 Numpy의 ndarray로 변형해서 써야하기 떄문에 as.Matrix를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# 레이블 -문자열을 One Hot Encoding을 사용해서 변환해준다.\n",
    "bclass = {\"thin\":[1,0,0], \"normal\":[0,1,0], \"fat\":[0,0,1]}\n",
    "y = np.empty((20000,3))\n",
    "for i, v in enumerate(csv[\"label\"]):\n",
    "    y[i] = bclass[v]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기 --- (※2)\n",
    "X_train, y_train = X[1:15001], y[1:15001]\n",
    "X_test,  y_test  = X[15001:20001], y[15001:20001] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀스 모델을 생성한 뒤 필요한 레이어를 추가하여 구성합니다.\n",
    "좀 더 복잡한 모델이 필요할 때는 케라스 함수 API를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://tykimos.github.io/warehouse/2017-1-27_MLP_Layer_Talk_neuron.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://tykimos.github.io/warehouse/2017-1-27_MLP_Layer_Talk_neuron.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x0, x1, x2 : 입력되는 뉴런의 축삭돌기로부터 전달되는 신호의 양\n",
    "- w0, w1, w2 : 시냅스의 강도, 즉 입력되는 뉴런의 영향력을 나타냅니다.\n",
    "- w0x0 + w1x1 + w2*x2 : 입력되는 신호의 양과 해당 신호의 시냅스 강도가 곱해진 값의 합계\n",
    "- f : 최종 합계가 다른 뉴런에게 전달되는 신호의 양을 결정짓는 규칙, 이를 활성화 함수라고 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0,0.5]) # 입력이 2개 (x1, x2)\n",
    "W1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]]) # 입력에 대응하는 weights \n",
    "B1 = np.array([0.1,0.2,0.3]) # bias\n",
    "\n",
    "print(X.shape) # 1x2\n",
    "print(W1.shape) # 2x3\n",
    "print(B1.shape)# 1x3\n",
    "\n",
    "\n",
    "#출처: http://3months.tistory.com/65 [Deep Play]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/resources/dims_types.html\n",
    "https://www.tensorflow.org/programmers_guide/tensors\n",
    "- Rank\tShape\tDimension number\tExample\n",
    "- 0\t[]\t0-D\tA 0-D tensor. A scalar.\n",
    "- 1\t[D0]\t1-D\tA 1-D tensor with shape [5].\n",
    "- 2\t[D0, D1]\t2-D\tA 2-D tensor with shape [3, 4].\n",
    "- 3\t[D0, D1, D2]\t3-D\tA 3-D tensor with shape [1, 4, 3].\n",
    "- n\t[D0, D1, ... Dn-1]\tn-D\tA tensor with shape [D0, D1, ... Dn-1].\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구조 정의하기 --- (※3)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2,))) #Just your regular densely-connected NN layer.\n",
    "# now the model will take as input arrays of shape (*, 2)\n",
    "# and output arrays of shape (*, 512)\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1)) #드롭 아웃은 오버피팅(over-fit)을 막기 위한 방법으로 뉴럴 네트워크가 학습중일때, 랜덤하게 뉴런을 꺼서 학습을 방해함으로써, 학습이 학습용 데이타에 치우치는 현상을 막아준다. \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습하기 전에 학습에 대한 설정을 수행합니다.\n",
    "손실 함수 및 최적화 방법을 정의합니다.\n",
    " - loss : 현재 가중치 세트를 평가하는 데 사용한 손실 함수 입니다. 다중 클래스 문제이므로 ‘categorical_crossentropy’으로 지정합니다.\n",
    " - optimizer : 최적의 가중치를 검색하는 데 사용되는 최적화 알고리즘으로 효율적인 경사 하강법 알고리즘 중 하나인 rmsprop 사용\n",
    "  - SGD: Stochastic Gradient Descent, 이 방법에서는 loss function을 계산할 때 전체 데이터(batch) 대신 일부 조그마한 데이터의 모음(mini-batch)에 대해서만 loss function을 계산한다\n",
    " - metrics : 평가 척도를 나타내며 분류 문제에서는 일반적으로 ‘accuracy’으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축하기 --- (※4)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "x : 입력 데이터\n",
    "y : 라벨 값\n",
    "batch_size : 몇 개의 샘플로 가중치를 갱신할 것인지 지정\n",
    "epochs : 학습 반복 횟수\n",
    "'''\n",
    "- Batch Size=100 : 전체 Train Set에 대해서 100개 단위로 나눈 후에, 100개기반으로 Fitting후 가중치를 변경\n",
    "- epochs =20: 같은 Train Set에 대한 Fitting을 20번씩 반복해서 가중치를 수정해나감\n",
    "- validation_split: 10%의 train set에 대해서는 남겨두었다가 매 epoch마다 해당 train_set을 기반으로 loss 및 기타 수치에 대해 evaluation\n",
    "- callback: 더 이상 개선의 여지가 없을 때 학습을 종료,  여기서는 fit 함수에서 EarlyStopping이라는 콜백함수가 학습 과정 중에 매번 호출됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "\r",
      "  100/13500 [..............................] - ETA: 1s - loss: 0.2005 - acc: 0.9300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  500/13500 [>.............................] - ETA: 1s - loss: 0.1195 - acc: 0.9500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1000/13500 [=>............................] - ETA: 1s - loss: 0.1315 - acc: 0.9480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1400/13500 [==>...........................] - ETA: 1s - loss: 0.1642 - acc: 0.9321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1800/13500 [===>..........................] - ETA: 1s - loss: 0.1535 - acc: 0.9383\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2200/13500 [===>..........................] - ETA: 1s - loss: 0.1469 - acc: 0.9400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2600/13500 [====>.........................] - ETA: 1s - loss: 0.1512 - acc: 0.9369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3100/13500 [=====>........................] - ETA: 1s - loss: 0.1459 - acc: 0.9400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3600/13500 [=======>......................] - ETA: 1s - loss: 0.1411 - acc: 0.9425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4100/13500 [========>.....................] - ETA: 1s - loss: 0.1465 - acc: 0.9393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4600/13500 [=========>....................] - ETA: 1s - loss: 0.1437 - acc: 0.9420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5000/13500 [==========>...................] - ETA: 1s - loss: 0.1465 - acc: 0.9400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5500/13500 [===========>..................] - ETA: 1s - loss: 0.1484 - acc: 0.9367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6000/13500 [============>.................] - ETA: 0s - loss: 0.1493 - acc: 0.9348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6400/13500 [=============>................] - ETA: 0s - loss: 0.1473 - acc: 0.9363\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6800/13500 [==============>...............] - ETA: 0s - loss: 0.1441 - acc: 0.9379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7200/13500 [===============>..............] - ETA: 0s - loss: 0.1432 - acc: 0.9376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7700/13500 [================>.............] - ETA: 0s - loss: 0.1485 - acc: 0.9353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8200/13500 [=================>............] - ETA: 0s - loss: 0.1448 - acc: 0.9372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8600/13500 [==================>...........] - ETA: 0s - loss: 0.1442 - acc: 0.9373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9000/13500 [===================>..........] - ETA: 0s - loss: 0.1428 - acc: 0.9379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9500/13500 [====================>.........] - ETA: 0s - loss: 0.1491 - acc: 0.9348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10000/13500 [=====================>........] - ETA: 0s - loss: 0.1471 - acc: 0.9361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10400/13500 [======================>.......] - ETA: 0s - loss: 0.1453 - acc: 0.9372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10900/13500 [=======================>......] - ETA: 0s - loss: 0.1491 - acc: 0.9348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11400/13500 [========================>.....] - ETA: 0s - loss: 0.1482 - acc: 0.9346\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11800/13500 [=========================>....] - ETA: 0s - loss: 0.1456 - acc: 0.9360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12300/13500 [==========================>...] - ETA: 0s - loss: 0.1438 - acc: 0.9369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12800/13500 [===========================>..] - ETA: 0s - loss: 0.1420 - acc: 0.9379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13300/13500 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13500/13500 [==============================] - 2s 129us/step - loss: 0.1445 - acc: 0.9375 - val_loss: 0.3670 - val_acc: 0.8393\n",
      "Epoch 2/20\n",
      "\r",
      "  100/13500 [..............................] - ETA: 1s - loss: 0.4213 - acc: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  600/13500 [>.............................] - ETA: 1s - loss: 0.1839 - acc: 0.9233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1100/13500 [=>............................] - ETA: 1s - loss: 0.1413 - acc: 0.9482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1600/13500 [==>...........................] - ETA: 1s - loss: 0.1278 - acc: 0.9538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2000/13500 [===>..........................] - ETA: 1s - loss: 0.1245 - acc: 0.9535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2500/13500 [====>.........................] - ETA: 1s - loss: 0.1200 - acc: 0.9560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2900/13500 [=====>........................] - ETA: 1s - loss: 0.1348 - acc: 0.9455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3400/13500 [======>.......................] - ETA: 1s - loss: 0.1299 - acc: 0.9491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3800/13500 [=======>......................] - ETA: 1s - loss: 0.1264 - acc: 0.9508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4300/13500 [========>.....................] - ETA: 1s - loss: 0.1353 - acc: 0.9477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4700/13500 [=========>....................] - ETA: 1s - loss: 0.1313 - acc: 0.9494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5200/13500 [==========>...................] - ETA: 0s - loss: 0.1255 - acc: 0.9527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5700/13500 [===========>..................] - ETA: 0s - loss: 0.1233 - acc: 0.9540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6200/13500 [============>.................] - ETA: 0s - loss: 0.1432 - acc: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6600/13500 [=============>................] - ETA: 0s - loss: 0.1396 - acc: 0.9470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7100/13500 [==============>...............] - ETA: 0s - loss: 0.1370 - acc: 0.9475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7600/13500 [===============>..............] - ETA: 0s - loss: 0.1358 - acc: 0.9474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8000/13500 [================>.............] - ETA: 0s - loss: 0.1365 - acc: 0.9461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8500/13500 [=================>............] - ETA: 0s - loss: 0.1377 - acc: 0.9447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8900/13500 [==================>...........] - ETA: 0s - loss: 0.1364 - acc: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9400/13500 [===================>..........] - ETA: 0s - loss: 0.1341 - acc: 0.9463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9900/13500 [=====================>........] - ETA: 0s - loss: 0.1351 - acc: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10400/13500 [======================>.......] - ETA: 0s - loss: 0.1374 - acc: 0.9434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10900/13500 [=======================>......] - ETA: 0s - loss: 0.1416 - acc: 0.9406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11400/13500 [========================>.....] - ETA: 0s - loss: 0.1393 - acc: 0.9416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11900/13500 [=========================>....] - ETA: 0s - loss: 0.1372 - acc: 0.9428\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12400/13500 [==========================>...] - ETA: 0s - loss: 0.1373 - acc: 0.9426\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12900/13500 [===========================>..] - ETA: 0s - loss: 0.1394 - acc: 0.9413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13400/13500 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9411\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13500/13500 [==============================] - 2s 122us/step - loss: 0.1384 - acc: 0.9415 - val_loss: 0.0791 - val_acc: 0.9713\n",
      "Epoch 3/20\n",
      "\r",
      "  100/13500 [..............................] - ETA: 1s - loss: 0.1209 - acc: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  600/13500 [>.............................] - ETA: 1s - loss: 0.1352 - acc: 0.9433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1000/13500 [=>............................] - ETA: 1s - loss: 0.1191 - acc: 0.9560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1500/13500 [==>...........................] - ETA: 1s - loss: 0.1496 - acc: 0.9367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1900/13500 [===>..........................] - ETA: 1s - loss: 0.1410 - acc: 0.9389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2400/13500 [====>.........................] - ETA: 1s - loss: 0.1292 - acc: 0.9454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2800/13500 [=====>........................] - ETA: 1s - loss: 0.1255 - acc: 0.9471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3300/13500 [======>.......................] - ETA: 1s - loss: 0.1286 - acc: 0.9439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3800/13500 [=======>......................] - ETA: 1s - loss: 0.1430 - acc: 0.9361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4300/13500 [========>.....................] - ETA: 1s - loss: 0.1382 - acc: 0.9391\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4700/13500 [=========>....................] - ETA: 1s - loss: 0.1397 - acc: 0.9374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5200/13500 [==========>...................] - ETA: 1s - loss: 0.1357 - acc: 0.9388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5600/13500 [===========>..................] - ETA: 0s - loss: 0.1339 - acc: 0.9396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6000/13500 [============>.................] - ETA: 0s - loss: 0.1417 - acc: 0.9355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6500/13500 [=============>................] - ETA: 0s - loss: 0.1388 - acc: 0.9366\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7000/13500 [==============>...............] - ETA: 0s - loss: 0.1411 - acc: 0.9350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7500/13500 [===============>..............] - ETA: 0s - loss: 0.1427 - acc: 0.9339\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8000/13500 [================>.............] - ETA: 0s - loss: 0.1392 - acc: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8500/13500 [=================>............] - ETA: 0s - loss: 0.1377 - acc: 0.9372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9000/13500 [===================>..........] - ETA: 0s - loss: 0.1397 - acc: 0.9369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9400/13500 [===================>..........] - ETA: 0s - loss: 0.1377 - acc: 0.9378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9800/13500 [====================>.........] - ETA: 0s - loss: 0.1357 - acc: 0.9382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10100/13500 [=====================>........] - ETA: 0s - loss: 0.1379 - acc: 0.9370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10500/13500 [======================>.......] - ETA: 0s - loss: 0.1364 - acc: 0.9379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11000/13500 [=======================>......] - ETA: 0s - loss: 0.1377 - acc: 0.9365\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11500/13500 [========================>.....] - ETA: 0s - loss: 0.1371 - acc: 0.9363\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12000/13500 [=========================>....] - ETA: 0s - loss: 0.1356 - acc: 0.9370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12500/13500 [==========================>...] - ETA: 0s - loss: 0.1364 - acc: 0.9370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12900/13500 [===========================>..] - ETA: 0s - loss: 0.1355 - acc: 0.9373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13400/13500 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13500/13500 [==============================] - 2s 126us/step - loss: 0.1368 - acc: 0.9366 - val_loss: 0.0810 - val_acc: 0.9747\n",
      "Epoch 4/20\n",
      "\r",
      "  100/13500 [..............................] - ETA: 1s - loss: 0.0597 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  600/13500 [>.............................] - ETA: 1s - loss: 0.0938 - acc: 0.9617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1100/13500 [=>............................] - ETA: 1s - loss: 0.1312 - acc: 0.9436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1600/13500 [==>...........................] - ETA: 1s - loss: 0.1172 - acc: 0.9525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2100/13500 [===>..........................] - ETA: 1s - loss: 0.1289 - acc: 0.9448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2600/13500 [====>.........................] - ETA: 1s - loss: 0.1309 - acc: 0.9450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3100/13500 [=====>........................] - ETA: 1s - loss: 0.1339 - acc: 0.9435\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3600/13500 [=======>......................] - ETA: 1s - loss: 0.1332 - acc: 0.9439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4000/13500 [=======>......................] - ETA: 1s - loss: 0.1366 - acc: 0.9413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4500/13500 [=========>....................] - ETA: 1s - loss: 0.1390 - acc: 0.9389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5000/13500 [==========>...................] - ETA: 0s - loss: 0.1315 - acc: 0.9432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5400/13500 [===========>..................] - ETA: 0s - loss: 0.1272 - acc: 0.9454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5900/13500 [============>.................] - ETA: 0s - loss: 0.1368 - acc: 0.9412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6400/13500 [=============>................] - ETA: 0s - loss: 0.1327 - acc: 0.9434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6900/13500 [==============>...............] - ETA: 0s - loss: 0.1325 - acc: 0.9430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7400/13500 [===============>..............] - ETA: 0s - loss: 0.1293 - acc: 0.9443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7800/13500 [================>.............] - ETA: 0s - loss: 0.1268 - acc: 0.9462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8300/13500 [=================>............] - ETA: 0s - loss: 0.1360 - acc: 0.9420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8800/13500 [==================>...........] - ETA: 0s - loss: 0.1333 - acc: 0.9436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9200/13500 [===================>..........] - ETA: 0s - loss: 0.1317 - acc: 0.9443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9600/13500 [====================>.........] - ETA: 0s - loss: 0.1318 - acc: 0.9441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10000/13500 [=====================>........] - ETA: 0s - loss: 0.1304 - acc: 0.9447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10400/13500 [======================>.......] - ETA: 0s - loss: 0.1345 - acc: 0.9424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10900/13500 [=======================>......] - ETA: 0s - loss: 0.1317 - acc: 0.9441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11400/13500 [========================>.....] - ETA: 0s - loss: 0.1292 - acc: 0.9455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11900/13500 [=========================>....] - ETA: 0s - loss: 0.1273 - acc: 0.9463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12400/13500 [==========================>...] - ETA: 0s - loss: 0.1310 - acc: 0.9448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12800/13500 [===========================>..] - ETA: 0s - loss: 0.1311 - acc: 0.9448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13300/13500 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13500/13500 [==============================] - 2s 122us/step - loss: 0.1282 - acc: 0.9463 - val_loss: 0.0678 - val_acc: 0.9813\n",
      "Epoch 5/20\n",
      "\r",
      "  100/13500 [..............................] - ETA: 1s - loss: 0.0357 - acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  600/13500 [>.............................] - ETA: 1s - loss: 0.0916 - acc: 0.9533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1100/13500 [=>............................] - ETA: 1s - loss: 0.0780 - acc: 0.9682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1600/13500 [==>...........................] - ETA: 1s - loss: 0.0789 - acc: 0.9713\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2100/13500 [===>..........................] - ETA: 1s - loss: 0.1438 - acc: 0.9443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2600/13500 [====>.........................] - ETA: 1s - loss: 0.1350 - acc: 0.9492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3100/13500 [=====>........................] - ETA: 1s - loss: 0.1250 - acc: 0.9529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3600/13500 [=======>......................] - ETA: 1s - loss: 0.1194 - acc: 0.9536\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4100/13500 [========>.....................] - ETA: 1s - loss: 0.1299 - acc: 0.9471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4600/13500 [=========>....................] - ETA: 1s - loss: 0.1246 - acc: 0.9493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5100/13500 [==========>...................] - ETA: 0s - loss: 0.1215 - acc: 0.9500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5500/13500 [===========>..................] - ETA: 0s - loss: 0.1239 - acc: 0.9476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6000/13500 [============>.................] - ETA: 0s - loss: 0.1229 - acc: 0.9480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6500/13500 [=============>................] - ETA: 0s - loss: 0.1201 - acc: 0.9495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7000/13500 [==============>...............] - ETA: 0s - loss: 0.1254 - acc: 0.9476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7500/13500 [===============>..............] - ETA: 0s - loss: 0.1232 - acc: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8000/13500 [================>.............] - ETA: 0s - loss: 0.1213 - acc: 0.9491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8400/13500 [=================>............] - ETA: 0s - loss: 0.1280 - acc: 0.9460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8900/13500 [==================>...........] - ETA: 0s - loss: 0.1264 - acc: 0.9464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9400/13500 [===================>..........] - ETA: 0s - loss: 0.1239 - acc: 0.9477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9900/13500 [=====================>........] - ETA: 0s - loss: 0.1225 - acc: 0.9482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10400/13500 [======================>.......] - ETA: 0s - loss: 0.1275 - acc: 0.9462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10900/13500 [=======================>......] - ETA: 0s - loss: 0.1244 - acc: 0.9479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11300/13500 [========================>.....] - ETA: 0s - loss: 0.1232 - acc: 0.9484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11800/13500 [=========================>....] - ETA: 0s - loss: 0.1275 - acc: 0.9461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12300/13500 [==========================>...] - ETA: 0s - loss: 0.1247 - acc: 0.9473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12800/13500 [===========================>..] - ETA: 0s - loss: 0.1228 - acc: 0.9482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13300/13500 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13500/13500 [==============================] - 2s 121us/step - loss: 0.1211 - acc: 0.9491 - val_loss: 0.3223 - val_acc: 0.8673\n",
      "Epoch 6/20\n",
      "\r",
      "  100/13500 [..............................] - ETA: 2s - loss: 0.2295 - acc: 0.8800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  600/13500 [>.............................] - ETA: 1s - loss: 0.1592 - acc: 0.9283\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1100/13500 [=>............................] - ETA: 1s - loss: 0.1420 - acc: 0.9336\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1600/13500 [==>...........................] - ETA: 1s - loss: 0.1423 - acc: 0.9337\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2100/13500 [===>..........................] - ETA: 1s - loss: 0.1364 - acc: 0.9352\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2600/13500 [====>.........................] - ETA: 1s - loss: 0.1313 - acc: 0.9385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3000/13500 [=====>........................] - ETA: 1s - loss: 0.1279 - acc: 0.9403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3500/13500 [======>.......................] - ETA: 1s - loss: 0.1373 - acc: 0.9354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4000/13500 [=======>......................] - ETA: 1s - loss: 0.1296 - acc: 0.9395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4400/13500 [========>.....................] - ETA: 1s - loss: 0.1251 - acc: 0.9425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4900/13500 [=========>....................] - ETA: 1s - loss: 0.1254 - acc: 0.9416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5400/13500 [===========>..................] - ETA: 0s - loss: 0.1320 - acc: 0.9387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5900/13500 [============>.................] - ETA: 0s - loss: 0.1269 - acc: 0.9420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6400/13500 [=============>................] - ETA: 0s - loss: 0.1260 - acc: 0.9430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6800/13500 [==============>...............] - ETA: 0s - loss: 0.1339 - acc: 0.9394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7300/13500 [===============>..............] - ETA: 0s - loss: 0.1322 - acc: 0.9397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7800/13500 [================>.............] - ETA: 0s - loss: 0.1281 - acc: 0.9424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8300/13500 [=================>............] - ETA: 0s - loss: 0.1289 - acc: 0.9413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8800/13500 [==================>...........] - ETA: 0s - loss: 0.1293 - acc: 0.9403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9200/13500 [===================>..........] - ETA: 0s - loss: 0.1268 - acc: 0.9417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9700/13500 [====================>.........] - ETA: 0s - loss: 0.1269 - acc: 0.9416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10200/13500 [=====================>........] - ETA: 0s - loss: 0.1261 - acc: 0.9422\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10700/13500 [======================>.......] - ETA: 0s - loss: 0.1263 - acc: 0.9421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11200/13500 [=======================>......] - ETA: 0s - loss: 0.1262 - acc: 0.9418\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11700/13500 [=========================>....] - ETA: 0s - loss: 0.1291 - acc: 0.9403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12100/13500 [=========================>....] - ETA: 0s - loss: 0.1269 - acc: 0.9416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12600/13500 [===========================>..] - ETA: 0s - loss: 0.1253 - acc: 0.9421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13100/13500 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9402\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13500/13500 [==============================] - 2s 121us/step - loss: 0.1274 - acc: 0.9410 - val_loss: 0.0690 - val_acc: 0.9713\n",
      "[0.1444820759748971, 0.13843641394266376, 0.13675384005462682, 0.12816096500114157, 0.12109545684523053, 0.12740122118481884]\n",
      "[0.93748148458975333, 0.94148148872234205, 0.93659259610705903, 0.94629630247751872, 0.94911111769852818, 0.94103704161114166]\n",
      "[0.36702858408292133, 0.079121753325064978, 0.080971002827088037, 0.067791391412417093, 0.32226961900790535, 0.069020888457695648]\n",
      "[0.8393333315849304, 0.97133334477742517, 0.97466667095820114, 0.98133333921432497, 0.86733333269755042, 0.9713333408037822]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 훈련하기 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=1)\n",
    "\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['acc'])\n",
    "print(hist.history['val_loss'])\n",
    "print(hist.history['val_acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_loss(노란색) : 훈련 손실값이며 x축은 에포크 수, 좌측 y축은 손실값을 나타냅니다.\n",
    "- val_loss(빨간색) : 검증 손실값이며 x축은 에포크 수, 좌측 y축은 손실값을 나타냅니다.\n",
    "- train_acc(파란색) : 훈련 정확도이며 x축은 에포크 수, 우측 y축은 정확도를 나타냅니다.\n",
    "- val_acc(녹색) : 검증 정확도이며 x축은 에포크 수, 우측 y축은 정확도를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEKCAYAAACYKLs6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJlr5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2062f3daa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준비된 시험셋으로 학습한 모델을 평가합니다.\n",
    "케라스에서는 evaluate() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  32/4999 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/4999 [===>..........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1536/4999 [========>.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2304/4999 [============>.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3168/4999 [==================>...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "4032/4999 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "4960/4999 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "4999/4999 [==============================] - 0s 63us/step\n",
      "loss= 0.168044076911\n",
      "accuracy= 0.912582516515\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 평가하기 --- (※6)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow로 비만도 판정해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기 --- (※1)\n",
    "csv = pd.read_csv(\"./ch5/bmi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>62</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177</td>\n",
       "      <td>61</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187</td>\n",
       "      <td>48</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>60</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight   label\n",
       "0     142      62     fat\n",
       "1     142      73     fat\n",
       "2     177      61  normal\n",
       "3     187      48    thin\n",
       "4     153      60     fat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csv.shape)\n",
    "csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.62</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.73</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.61</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.48</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.60</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight   label\n",
       "0   0.710    0.62     fat\n",
       "1   0.710    0.73     fat\n",
       "2   0.885    0.61  normal\n",
       "3   0.935    0.48    thin\n",
       "4   0.765    0.60     fat"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 정규화 --- (※2)\n",
    "csv[\"height\"] = csv[\"height\"] / 200\n",
    "csv[\"weight\"] = csv[\"weight\"] / 100\n",
    "\n",
    "csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 배열로 변환하기 --- (※3)\n",
    "# - thin=(1,0,0) / normal=(0,1,0) / fat=(0,0,1)\n",
    "bclass = {\"thin\": [1,0,0], \"normal\": [0,1,0], \"fat\": [0,0,1]}\n",
    "csv[\"label_pat\"] = csv[\"label\"].apply(lambda x : np.array(bclass[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 위한 데이터 분류 --- (※4)\n",
    "test_csv = csv[15000:20000]\n",
    "test_pat = test_csv[[\"weight\",\"height\"]]\n",
    "test_ans = list(test_csv[\"label_pat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 플로우 그래프 구출하기 --- (※5)\n",
    "# 플레이스홀더 선언하기\n",
    "x  = tf.placeholder(tf.float32, [None, 2]) # 키와 몸무게 데이터 넣기\n",
    "y_ = tf.placeholder(tf.float32, [None, 3]) # 정답 레이블 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 선언하기 --- (※6)\n",
    "W = tf.Variable(tf.zeros([2, 3])); # 가중치\n",
    "b = tf.Variable(tf.zeros([3])); # 바이어스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 회귀 정의하기 --- (※7)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "# Softmax(소프트맥스)는 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAxNzA2MDVfNDMg/MDAxNDk2NTkwNTY2Njcx.-soSHRQ2urRoHGkkQk-OmHJ1HJIvpS3YuO1SXeecBAQg.LVPXD-PxQ5o8mK9uPMkqvp18vwjyKUypfRfYlqTv_B8g.JPEG.wideeyed/softmax_f.jpg?type=w2\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://mblogthumb-phinf.pstatic.net/MjAxNzA2MDVfNDMg/MDAxNDk2NTkwNTY2Njcx.-soSHRQ2urRoHGkkQk-OmHJ1HJIvpS3YuO1SXeecBAQg.LVPXD-PxQ5o8mK9uPMkqvp18vwjyKUypfRfYlqTv_B8g.JPEG.wideeyed/softmax_f.jpg?type=w2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 입력값의 대소 순서가 출력값의 대소 순서와 같다는 것을 알 수 있다.\n",
    " - 결국 가장 큰 값은 이미 소프트맥스 이전에 가장 큰 값이였다. \n",
    " - 따라서 추론(운영)단계에서 연산속도를 빠르기하기 위해 생략하기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련하기 --- (※8)\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답률 구하기\n",
    "predict = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 시작하기\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 변수 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AggregationMethod',\n",
       " 'Assert',\n",
       " 'AttrValue',\n",
       " 'COMPILER_VERSION',\n",
       " 'ConditionalAccumulator',\n",
       " 'ConditionalAccumulatorBase',\n",
       " 'ConfigProto',\n",
       " 'DType',\n",
       " 'DeviceSpec',\n",
       " 'Dimension',\n",
       " 'Event',\n",
       " 'FIFOQueue',\n",
       " 'FixedLenFeature',\n",
       " 'FixedLenSequenceFeature',\n",
       " 'FixedLengthRecordReader',\n",
       " 'GIT_VERSION',\n",
       " 'GPUOptions',\n",
       " 'GRAPH_DEF_VERSION',\n",
       " 'GRAPH_DEF_VERSION_MIN_CONSUMER',\n",
       " 'GRAPH_DEF_VERSION_MIN_PRODUCER',\n",
       " 'Graph',\n",
       " 'GraphDef',\n",
       " 'GraphKeys',\n",
       " 'GraphOptions',\n",
       " 'HistogramProto',\n",
       " 'IdentityReader',\n",
       " 'IndexedSlices',\n",
       " 'InteractiveSession',\n",
       " 'LogMessage',\n",
       " 'MetaGraphDef',\n",
       " 'NameAttrList',\n",
       " 'NoGradient',\n",
       " 'NodeDef',\n",
       " 'NotDifferentiable',\n",
       " 'OpError',\n",
       " 'Operation',\n",
       " 'OptimizerOptions',\n",
       " 'PaddingFIFOQueue',\n",
       " 'Print',\n",
       " 'PriorityQueue',\n",
       " 'QUANTIZED_DTYPES',\n",
       " 'QueueBase',\n",
       " 'RandomShuffleQueue',\n",
       " 'ReaderBase',\n",
       " 'RegisterGradient',\n",
       " 'RunMetadata',\n",
       " 'RunOptions',\n",
       " 'Session',\n",
       " 'SessionLog',\n",
       " 'SparseConditionalAccumulator',\n",
       " 'SparseFeature',\n",
       " 'SparseTensor',\n",
       " 'SparseTensorValue',\n",
       " 'Summary',\n",
       " 'TFRecordReader',\n",
       " 'Tensor',\n",
       " 'TensorArray',\n",
       " 'TensorInfo',\n",
       " 'TensorShape',\n",
       " 'TextLineReader',\n",
       " 'VERSION',\n",
       " 'VarLenFeature',\n",
       " 'Variable',\n",
       " 'VariableScope',\n",
       " 'WholeFileReader',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__compiler_version__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__git_version__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'abs',\n",
       " 'accumulate_n',\n",
       " 'acos',\n",
       " 'add',\n",
       " 'add_check_numerics_ops',\n",
       " 'add_n',\n",
       " 'add_to_collection',\n",
       " 'all_variables',\n",
       " 'app',\n",
       " 'arg_max',\n",
       " 'arg_min',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'as_dtype',\n",
       " 'as_string',\n",
       " 'asin',\n",
       " 'assert_equal',\n",
       " 'assert_greater',\n",
       " 'assert_greater_equal',\n",
       " 'assert_integer',\n",
       " 'assert_less',\n",
       " 'assert_less_equal',\n",
       " 'assert_negative',\n",
       " 'assert_non_negative',\n",
       " 'assert_non_positive',\n",
       " 'assert_none_equal',\n",
       " 'assert_positive',\n",
       " 'assert_proper_iterable',\n",
       " 'assert_rank',\n",
       " 'assert_rank_at_least',\n",
       " 'assert_same_float_dtype',\n",
       " 'assert_scalar',\n",
       " 'assert_type',\n",
       " 'assert_variables_initialized',\n",
       " 'assign',\n",
       " 'assign_add',\n",
       " 'assign_sub',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'batch_to_space',\n",
       " 'batch_to_space_nd',\n",
       " 'betainc',\n",
       " 'bfloat16',\n",
       " 'bincount',\n",
       " 'bitcast',\n",
       " 'bool',\n",
       " 'boolean_mask',\n",
       " 'broadcast_dynamic_shape',\n",
       " 'broadcast_static_shape',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'ceil',\n",
       " 'check_numerics',\n",
       " 'cholesky',\n",
       " 'cholesky_solve',\n",
       " 'clip_by_average_norm',\n",
       " 'clip_by_global_norm',\n",
       " 'clip_by_norm',\n",
       " 'clip_by_value',\n",
       " 'compat',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex64',\n",
       " 'concat',\n",
       " 'cond',\n",
       " 'confusion_matrix',\n",
       " 'conj',\n",
       " 'constant',\n",
       " 'constant_initializer',\n",
       " 'container',\n",
       " 'contrib',\n",
       " 'control_dependencies',\n",
       " 'convert_to_tensor',\n",
       " 'convert_to_tensor_or_indexed_slices',\n",
       " 'convert_to_tensor_or_sparse_tensor',\n",
       " 'cos',\n",
       " 'count_nonzero',\n",
       " 'count_up_to',\n",
       " 'create_partitioned_variables',\n",
       " 'cross',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'decode_base64',\n",
       " 'decode_csv',\n",
       " 'decode_json_example',\n",
       " 'decode_raw',\n",
       " 'delete_session_tensor',\n",
       " 'depth_to_space',\n",
       " 'dequantize',\n",
       " 'deserialize_many_sparse',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_part',\n",
       " 'digamma',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'double',\n",
       " 'dynamic_partition',\n",
       " 'dynamic_stitch',\n",
       " 'edit_distance',\n",
       " 'einsum',\n",
       " 'encode_base64',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erfc',\n",
       " 'errors',\n",
       " 'estimator',\n",
       " 'exp',\n",
       " 'expand_dims',\n",
       " 'expm1',\n",
       " 'extract_image_patches',\n",
       " 'eye',\n",
       " 'fake_quant_with_min_max_args',\n",
       " 'fake_quant_with_min_max_args_gradient',\n",
       " 'fake_quant_with_min_max_vars',\n",
       " 'fake_quant_with_min_max_vars_gradient',\n",
       " 'fake_quant_with_min_max_vars_per_channel',\n",
       " 'fake_quant_with_min_max_vars_per_channel_gradient',\n",
       " 'feature_column',\n",
       " 'fft',\n",
       " 'fft2d',\n",
       " 'fft3d',\n",
       " 'fill',\n",
       " 'fixed_size_partitioner',\n",
       " 'flags',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'floor',\n",
       " 'floor_div',\n",
       " 'floordiv',\n",
       " 'floormod',\n",
       " 'foldl',\n",
       " 'foldr',\n",
       " 'gather',\n",
       " 'gather_nd',\n",
       " 'get_collection',\n",
       " 'get_collection_ref',\n",
       " 'get_default_graph',\n",
       " 'get_default_session',\n",
       " 'get_local_variable',\n",
       " 'get_seed',\n",
       " 'get_session_handle',\n",
       " 'get_session_tensor',\n",
       " 'get_variable',\n",
       " 'get_variable_scope',\n",
       " 'gfile',\n",
       " 'global_norm',\n",
       " 'global_variables',\n",
       " 'global_variables_initializer',\n",
       " 'gradients',\n",
       " 'graph_util',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'group',\n",
       " 'half',\n",
       " 'hessians',\n",
       " 'histogram_fixed_width',\n",
       " 'identity',\n",
       " 'ifft',\n",
       " 'ifft2d',\n",
       " 'ifft3d',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'imag',\n",
       " 'image',\n",
       " 'import_graph_def',\n",
       " 'initialize_all_tables',\n",
       " 'initialize_all_variables',\n",
       " 'initialize_local_variables',\n",
       " 'initialize_variables',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'invert_permutation',\n",
       " 'is_finite',\n",
       " 'is_inf',\n",
       " 'is_nan',\n",
       " 'is_non_decreasing',\n",
       " 'is_numeric_tensor',\n",
       " 'is_strictly_increasing',\n",
       " 'is_variable_initialized',\n",
       " 'layers',\n",
       " 'lbeta',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'lin_space',\n",
       " 'linspace',\n",
       " 'load_file_system_library',\n",
       " 'load_op_library',\n",
       " 'local_variables',\n",
       " 'local_variables_initializer',\n",
       " 'log',\n",
       " 'log1p',\n",
       " 'log_sigmoid',\n",
       " 'logging',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'losses',\n",
       " 'make_ndarray',\n",
       " 'make_template',\n",
       " 'make_tensor_proto',\n",
       " 'map_fn',\n",
       " 'matching_files',\n",
       " 'matmul',\n",
       " 'matrix_band_part',\n",
       " 'matrix_determinant',\n",
       " 'matrix_diag',\n",
       " 'matrix_diag_part',\n",
       " 'matrix_inverse',\n",
       " 'matrix_set_diag',\n",
       " 'matrix_solve',\n",
       " 'matrix_solve_ls',\n",
       " 'matrix_transpose',\n",
       " 'matrix_triangular_solve',\n",
       " 'maximum',\n",
       " 'meshgrid',\n",
       " 'metrics',\n",
       " 'min_max_variable_partitioner',\n",
       " 'minimum',\n",
       " 'mod',\n",
       " 'model_variables',\n",
       " 'moving_average_variables',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'name_scope',\n",
       " 'negative',\n",
       " 'newaxis',\n",
       " 'nn',\n",
       " 'no_op',\n",
       " 'no_regularizer',\n",
       " 'norm',\n",
       " 'not_equal',\n",
       " 'one_hot',\n",
       " 'ones',\n",
       " 'ones_initializer',\n",
       " 'ones_like',\n",
       " 'op_scope',\n",
       " 'orthogonal_initializer',\n",
       " 'pad',\n",
       " 'parallel_stack',\n",
       " 'parse_example',\n",
       " 'parse_single_example',\n",
       " 'parse_single_sequence_example',\n",
       " 'parse_tensor',\n",
       " 'placeholder',\n",
       " 'placeholder_with_default',\n",
       " 'polygamma',\n",
       " 'pow',\n",
       " 'py_func',\n",
       " 'python_io',\n",
       " 'pywrap_tensorflow',\n",
       " 'qint16',\n",
       " 'qint32',\n",
       " 'qint8',\n",
       " 'qr',\n",
       " 'quantize_v2',\n",
       " 'quantized_concat',\n",
       " 'quint16',\n",
       " 'quint8',\n",
       " 'random_crop',\n",
       " 'random_gamma',\n",
       " 'random_normal',\n",
       " 'random_normal_initializer',\n",
       " 'random_poisson',\n",
       " 'random_shuffle',\n",
       " 'random_uniform',\n",
       " 'random_uniform_initializer',\n",
       " 'range',\n",
       " 'rank',\n",
       " 'read_file',\n",
       " 'real',\n",
       " 'realdiv',\n",
       " 'reciprocal',\n",
       " 'reduce_all',\n",
       " 'reduce_any',\n",
       " 'reduce_join',\n",
       " 'reduce_logsumexp',\n",
       " 'reduce_max',\n",
       " 'reduce_mean',\n",
       " 'reduce_min',\n",
       " 'reduce_prod',\n",
       " 'reduce_sum',\n",
       " 'register_tensor_conversion_function',\n",
       " 'report_uninitialized_variables',\n",
       " 'required_space_to_batch_paddings',\n",
       " 'reset_default_graph',\n",
       " 'reshape',\n",
       " 'resource',\n",
       " 'resource_loader',\n",
       " 'reverse',\n",
       " 'reverse_sequence',\n",
       " 'reverse_v2',\n",
       " 'rint',\n",
       " 'round',\n",
       " 'rsqrt',\n",
       " 'saturate_cast',\n",
       " 'saved_model',\n",
       " 'scalar_mul',\n",
       " 'scan',\n",
       " 'scatter_add',\n",
       " 'scatter_div',\n",
       " 'scatter_mul',\n",
       " 'scatter_nd',\n",
       " 'scatter_nd_add',\n",
       " 'scatter_nd_sub',\n",
       " 'scatter_nd_update',\n",
       " 'scatter_sub',\n",
       " 'scatter_update',\n",
       " 'segment_max',\n",
       " 'segment_mean',\n",
       " 'segment_min',\n",
       " 'segment_prod',\n",
       " 'segment_sum',\n",
       " 'self_adjoint_eig',\n",
       " 'self_adjoint_eigvals',\n",
       " 'sequence_mask',\n",
       " 'serialize_many_sparse',\n",
       " 'serialize_sparse',\n",
       " 'set_random_seed',\n",
       " 'setdiff1d',\n",
       " 'sets',\n",
       " 'shape',\n",
       " 'shape_n',\n",
       " 'sigmoid',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'size',\n",
       " 'slice',\n",
       " 'space_to_batch',\n",
       " 'space_to_batch_nd',\n",
       " 'space_to_depth',\n",
       " 'sparse_add',\n",
       " 'sparse_concat',\n",
       " 'sparse_fill_empty_rows',\n",
       " 'sparse_mask',\n",
       " 'sparse_matmul',\n",
       " 'sparse_maximum',\n",
       " 'sparse_merge',\n",
       " 'sparse_minimum',\n",
       " 'sparse_placeholder',\n",
       " 'sparse_reduce_sum',\n",
       " 'sparse_reduce_sum_sparse',\n",
       " 'sparse_reorder',\n",
       " 'sparse_reset_shape',\n",
       " 'sparse_reshape',\n",
       " 'sparse_retain',\n",
       " 'sparse_segment_mean',\n",
       " 'sparse_segment_sqrt_n',\n",
       " 'sparse_segment_sum',\n",
       " 'sparse_softmax',\n",
       " 'sparse_split',\n",
       " 'sparse_tensor_dense_matmul',\n",
       " 'sparse_tensor_to_dense',\n",
       " 'sparse_to_dense',\n",
       " 'sparse_to_indicator',\n",
       " 'sparse_transpose',\n",
       " 'spectral',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squared_difference',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'stop_gradient',\n",
       " 'strided_slice',\n",
       " 'string',\n",
       " 'string_join',\n",
       " 'string_split',\n",
       " 'string_to_hash_bucket',\n",
       " 'string_to_hash_bucket_fast',\n",
       " 'string_to_hash_bucket_strong',\n",
       " 'string_to_number',\n",
       " 'substr',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'svd',\n",
       " 'sysconfig',\n",
       " 'tables_initializer',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tensordot',\n",
       " 'test',\n",
       " 'tile',\n",
       " 'to_bfloat16',\n",
       " 'to_double',\n",
       " 'to_float',\n",
       " 'to_int32',\n",
       " 'to_int64',\n",
       " 'trace',\n",
       " 'train',\n",
       " 'trainable_variables',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncated_normal',\n",
       " 'truncated_normal_initializer',\n",
       " 'truncatediv',\n",
       " 'truncatemod',\n",
       " 'tuple',\n",
       " 'uint16',\n",
       " 'uint8',\n",
       " 'uniform_unit_scaling_initializer',\n",
       " 'unique',\n",
       " 'unique_with_counts',\n",
       " 'unsorted_segment_max',\n",
       " 'unsorted_segment_sum',\n",
       " 'unstack',\n",
       " 'user_ops',\n",
       " 'variable_axis_size_partitioner',\n",
       " 'variable_op_scope',\n",
       " 'variable_scope',\n",
       " 'variables_initializer',\n",
       " 'verify_tensor_all_finite',\n",
       " 'where',\n",
       " 'while_loop',\n",
       " 'write_file',\n",
       " 'zeros',\n",
       " 'zeros_initializer',\n",
       " 'zeros_like',\n",
       " 'zeta']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 cre= 18.2848 acc= 0.981\n",
      "step= 500 cre= 20.5722 acc= 0.9782\n",
      "step= 1000 cre= 17.6878 acc= 0.981\n",
      "step= 1500 cre= 19.8987 acc= 0.9786\n",
      "step= 2000 cre= 16.6885 acc= 0.9794\n",
      "step= 2500 cre= 18.0247 acc= 0.9812\n",
      "step= 3000 cre= 13.3752 acc= 0.9778\n"
     ]
    }
   ],
   "source": [
    "# 학습시키기\n",
    "for step in range(3500):\n",
    "    i = (step * 100) % 14000\n",
    "    rows = csv[1 + i : 1 + i + 100]\n",
    "    x_pat = rows[[\"weight\",\"height\"]]\n",
    "    y_ans = list(rows[\"label_pat\"])\n",
    "    fd = {x: x_pat, y_: y_ans}\n",
    "    sess.run(train, feed_dict=fd)\n",
    "    if step % 500 == 0:\n",
    "        cre = sess.run(cross_entropy, feed_dict=fd)\n",
    "        acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "        print(\"step=\", step, \"cre=\", cre, \"acc=\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종적인 정답률 구하기\n",
    "acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "print(\"정답률 =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
