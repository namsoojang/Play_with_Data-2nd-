{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    " - Machine Learning 라이브러리 Theano와 TesnorFlow를 Wrapping한 라이브러리 (https://deeplearning4j.org/kr/compare-dl4j-torch7-pylearn)\n",
    "  - Theano는 Numpy와 같은 다차원 배열을 다루는 라이브러리\n",
    "  - Tensorflow는 Theano를 대체하기 위해 나온 라이브러리\n",
    " - 케라스는 파이썬으로 구현된 쉽고 간결한 딥러닝 라이브러리입니다. 딥러닝 비전문가라도 각자 분야에서 손쉽게 딥러닝 모델을 개발하고 활용할 수 있도록 케라스는 직관적인 API를 제공하고 있습니다. 내부적으로는 텐서플로우(TensorFlow), 티아노(Theano), CNTK 등의 딥러닝 전용 엔진이 구동되지만 케라스 사용자는 복잡한 내부 엔진을 알 필요는 없습니다. 직관적인 API로 쉽게 다층퍼셉트론 모델, 컨볼루션 신경망 모델, 순환 신경망 모델 또는 이를 조합한 모델은 물론 다중 입력 또는 다중 출력 등 다양한 구성을 할 수 있습니다. (https://tykimos.github.io/2017/01/27/Keras_Talk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras로 비만도 판정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd, numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tomato/projects/Play_with_Data_2nd/5. 딥러닝'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BMI 데이터를 읽어 들이고 정규화하기 --- (※1)\n",
    "csv = pd.read_csv(\"./ch5/bmi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>62</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177</td>\n",
       "      <td>61</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187</td>\n",
       "      <td>48</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>60</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight   label\n",
       "0     142      62     fat\n",
       "1     142      73     fat\n",
       "2     177      61  normal\n",
       "3     187      48    thin\n",
       "4     153      60     fat"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csv.shape)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0062    0.00355 ]\n",
      " [ 0.0073    0.00355 ]\n",
      " [ 0.0061    0.004425]\n",
      " ..., \n",
      " [ 0.0037    0.004825]\n",
      " [ 0.0051    0.004875]\n",
      " [ 0.0067    0.004075]]\n"
     ]
    }
   ],
   "source": [
    "# 몸무게와 키 데이터 - 정규화: 데이터의 범위를 일치시키거나 분포를 유사하게 만들어 주기\n",
    "csv[\"weight\"] /= 100\n",
    "csv[\"height\"] /= 200\n",
    "X = csv[[\"weight\", \"height\"]].as_matrix() # --- (※1a)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas의 DataFrame형을 Keras에서는 Numpy의 ndarray로 변형해서 써야하기 떄문에 as.Matrix를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# 레이블 -문자열을 One Hot Encoding을 사용해서 변환해준다.\n",
    "bclass = {\"thin\":[1,0,0], \"normal\":[0,1,0], \"fat\":[0,0,1]}\n",
    "y = np.empty((20000,3))\n",
    "for i, v in enumerate(csv[\"label\"]):\n",
    "    y[i] = bclass[v]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기 --- (※2)\n",
    "X_train, y_train = X[1:15001], y[1:15001]\n",
    "X_test,  y_test  = X[15001:20001], y[15001:20001] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀스 모델을 생성한 뒤 필요한 레이어를 추가하여 구성합니다.\n",
    "좀 더 복잡한 모델이 필요할 때는 케라스 함수 API를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://tykimos.github.io/warehouse/2017-1-27_MLP_Layer_Talk_neuron.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://tykimos.github.io/warehouse/2017-1-27_MLP_Layer_Talk_neuron.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x0, x1, x2 : 입력되는 뉴런의 축삭돌기로부터 전달되는 신호의 양\n",
    "- w0, w1, w2 : 시냅스의 강도, 즉 입력되는 뉴런의 영향력을 나타냅니다.\n",
    "- w0x0 + w1x1 + w2*x2 : 입력되는 신호의 양과 해당 신호의 시냅스 강도가 곱해진 값의 합계\n",
    "- f : 최종 합계가 다른 뉴런에게 전달되는 신호의 양을 결정짓는 규칙, 이를 활성화 함수라고 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0,0.5]) # 입력이 2개 (x1, x2)\n",
    "W1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]]) # 입력에 대응하는 weights \n",
    "B1 = np.array([0.1,0.2,0.3]) # bias\n",
    "\n",
    "print(X.shape) # 1x2\n",
    "print(W1.shape) # 2x3\n",
    "print(B1.shape)# 1x3\n",
    "\n",
    "\n",
    "#출처: http://3months.tistory.com/65 [Deep Play]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/resources/dims_types.html\n",
    "https://www.tensorflow.org/programmers_guide/tensors\n",
    "- Rank\tShape\tDimension number\tExample\n",
    "- 0\t[]\t0-D\tA 0-D tensor. A scalar.\n",
    "- 1\t[D0]\t1-D\tA 1-D tensor with shape [5].\n",
    "- 2\t[D0, D1]\t2-D\tA 2-D tensor with shape [3, 4].\n",
    "- 3\t[D0, D1, D2]\t3-D\tA 3-D tensor with shape [1, 4, 3].\n",
    "- n\t[D0, D1, ... Dn-1]\tn-D\tA tensor with shape [D0, D1, ... Dn-1].\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모델 구조 정의하기 --- (※3)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2,))) \n",
    "# Just your regular densely-connected NN layer.\n",
    "# now the model will take as input arrays of shape (*, 2)\n",
    "# and output arrays of shape (*, 512)\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1)) #드롭 아웃은 오버피팅(over-fit)을 막기 위한 방법으로 뉴럴 네트워크가 학습중일때, 랜덤하게 뉴런을 꺼서 학습을 방해함으로써, 학습이 학습용 데이타에 치우치는 현상을 막아준다. \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습하기 전에 학습에 대한 설정을 수행합니다.\n",
    "손실 함수 및 최적화 방법을 정의합니다.\n",
    " - loss : 현재 가중치 세트를 평가하는 데 사용한 손실 함수 입니다. 다중 클래스 문제이므로 ‘categorical_crossentropy’으로 지정합니다.\n",
    " - optimizer : 최적의 가중치를 검색하는 데 사용되는 최적화 알고리즘으로 효율적인 경사 하강법 알고리즘 중 하나인 rmsprop 사용\n",
    "  - SGD: Stochastic Gradient Descent, 이 방법에서는 loss function을 계산할 때 전체 데이터(batch) 대신 일부 조그마한 데이터의 모음(mini-batch)에 대해서만 loss function을 계산한다\n",
    " - metrics : 평가 척도를 나타내며 분류 문제에서는 일반적으로 ‘accuracy’으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모델 구축하기 --- (※4)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "x : 입력 데이터\n",
    "y : 라벨 값\n",
    "batch_size : 몇 개의 샘플로 가중치를 갱신할 것인지 지정\n",
    "epochs : 학습 반복 횟수\n",
    "'''\n",
    "- Batch Size=100 : 전체 Train Set에 대해서 100개 단위로 나눈 후에, 100개기반으로 Fitting후 가중치를 변경\n",
    "- epochs =20: 같은 Train Set에 대한 Fitting을 20번씩 반복해서 가중치를 수정해나감\n",
    "- validation_split: 10%의 train set에 대해서는 남겨두었다가 매 epoch마다 해당 train_set을 기반으로 loss 및 기타 수치에 대해 evaluation\n",
    "- callback: 더 이상 개선의 여지가 없을 때 학습을 종료,  여기서는 fit 함수에서 EarlyStopping이라는 콜백함수가 학습 과정 중에 매번 호출됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 훈련하기 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=1)\n",
    "\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['acc'])\n",
    "print(hist.history['val_loss'])\n",
    "print(hist.history['val_acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_loss(노란색) : 훈련 손실값이며 x축은 에포크 수, 좌측 y축은 손실값을 나타냅니다.\n",
    "- val_loss(빨간색) : 검증 손실값이며 x축은 에포크 수, 좌측 y축은 손실값을 나타냅니다.\n",
    "- train_acc(파란색) : 훈련 정확도이며 x축은 에포크 수, 우측 y축은 정확도를 나타냅니다.\n",
    "- val_acc(녹색) : 검증 정확도이며 x축은 에포크 수, 우측 y축은 정확도를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준비된 시험셋으로 학습한 모델을 평가합니다.\n",
    "케라스에서는 evaluate() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 평가하기 --- (※6)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow로 비만도 판정해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기 --- (※1)\n",
    "csv = pd.read_csv(\"./ch5/bmi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csv.shape)\n",
    "csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 --- (※2)\n",
    "csv[\"height\"] = csv[\"height\"] / 200\n",
    "csv[\"weight\"] = csv[\"weight\"] / 100\n",
    "\n",
    "csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 레이블을 배열로 변환하기 --- (※3)\n",
    "# - thin=(1,0,0) / normal=(0,1,0) / fat=(0,0,1)\n",
    "bclass = {\"thin\": [1,0,0], \"normal\": [0,1,0], \"fat\": [0,0,1]}\n",
    "csv[\"label_pat\"] = csv[\"label\"].apply(lambda x : np.array(bclass[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 테스트를 위한 데이터 분류 --- (※4)\n",
    "test_csv = csv[15000:20000]\n",
    "test_pat = test_csv[[\"weight\",\"height\"]]\n",
    "test_ans = list(test_csv[\"label_pat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 플로우 그래프 구출하기 --- (※5)\n",
    "# 플레이스홀더 선언하기\n",
    "x  = tf.placeholder(tf.float32, [None, 2]) # 키와 몸무게 데이터 넣기\n",
    "y_ = tf.placeholder(tf.float32, [None, 3]) # 정답 레이블 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수 선언하기 --- (※6)\n",
    "W = tf.Variable(tf.zeros([2, 3])); # 가중치\n",
    "b = tf.Variable(tf.zeros([3])); # 바이어스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 소프트맥스 회귀 정의하기 --- (※7)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "# Softmax(소프트맥스)는 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://mblogthumb-phinf.pstatic.net/MjAxNzA2MDVfNDMg/MDAxNDk2NTkwNTY2Njcx.-soSHRQ2urRoHGkkQk-OmHJ1HJIvpS3YuO1SXeecBAQg.LVPXD-PxQ5o8mK9uPMkqvp18vwjyKUypfRfYlqTv_B8g.JPEG.wideeyed/softmax_f.jpg?type=w2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 입력값의 대소 순서가 출력값의 대소 순서와 같다는 것을 알 수 있다.\n",
    " - 결국 가장 큰 값은 이미 소프트맥스 이전에 가장 큰 값이였다. \n",
    " - 따라서 추론(운영)단계에서 연산속도를 빠르기하기 위해 생략하기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모델 훈련하기 --- (※8)\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 정답률 구하기\n",
    "predict = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 세션 시작하기\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 변수 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시키기\n",
    "for step in range(3500):\n",
    "    i = (step * 100) % 14000\n",
    "    rows = csv[1 + i : 1 + i + 100]\n",
    "    x_pat = rows[[\"weight\",\"height\"]]\n",
    "    y_ans = list(rows[\"label_pat\"])\n",
    "    fd = {x: x_pat, y_: y_ans}\n",
    "    sess.run(train, feed_dict=fd)\n",
    "    if step % 500 == 0:\n",
    "        cre = sess.run(cross_entropy, feed_dict=fd)\n",
    "        acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "        print(\"step=\", step, \"cre=\", cre, \"acc=\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 최종적인 정답률 구하기\n",
    "acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "print(\"정답률 =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
